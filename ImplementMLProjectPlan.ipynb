{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Implement Your Machine Learning Project Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will implement the machine learning project plan you created in the written assignment. You will:\n",
    "\n",
    "1. Load your data set and save it to a Pandas DataFrame.\n",
    "2. Perform exploratory data analysis on your data to determine which feature engineering and data preparation techniques you will use.\n",
    "3. Prepare your data for your model and create features and a label.\n",
    "4. Fit your model to the training data and evaluate your model.\n",
    "5. Improve your model by performing model selection and/or feature selection techniques to find best model for your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "Before you get started, import a few packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load the Data Set\n",
    "\n",
    "\n",
    "You have chosen to work with one of four data sets. The data sets are located in a folder named \"data.\" The file names of the three data sets are as follows:\n",
    "\n",
    "* The \"adult\" data set that contains Census information from 1994 is located in file `adultData.csv`\n",
    "* The airbnb NYC \"listings\" data set is located in file  `airbnbListingsData.csv`\n",
    "* The World Happiness Report (WHR) data set is located in file `WHR2018Chapter2OnlineData.csv`\n",
    "* The book review data set is located in file `bookReviewsData.csv`\n",
    "\n",
    "\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load your data using `pd.read_csv()` and save it to DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "df = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis\n",
    "\n",
    "The next step is to inspect and analyze your data set with your machine learning problem and project plan in mind. \n",
    "\n",
    "This step will help you determine data preparation and feature engineering techniques you will need to apply to your data to build a balanced modeling data set for your problem and model. These data preparation techniques may include:\n",
    "* addressing missingness, such as replacing missing values with means\n",
    "* renaming features and labels\n",
    "* finding and replacing outliers\n",
    "* performing winsorization if needed\n",
    "* performing one-hot encoding on categorical features\n",
    "* performing vectorization for an NLP problem\n",
    "* addressing class imbalance in your data sample to promote fair AI\n",
    "\n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. \n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was perhaps the best of Johannes Steinhof...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This very fascinating book is a story written ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The four tales in this collection are beautifu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The book contained more profanity than I expec...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have now entered a second time of deep conc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive Review\n",
       "0  This was perhaps the best of Johannes Steinhof...             True\n",
       "1  This very fascinating book is a story written ...             True\n",
       "2  The four tales in this collection are beautifu...             True\n",
       "3  The book contained more profanity than I expec...            False\n",
       "4  We have now entered a second time of deep conc...             True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1973, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Positive Review']\n",
    "X = df['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This was perhaps the best of Johannes Steinhof...\n",
       "1    This very fascinating book is a story written ...\n",
       "2    The four tales in this collection are beautifu...\n",
       "3    The book contained more profanity than I expec...\n",
       "4    We have now entered a second time of deep conc...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1973,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1369    As my brother said when flipping through this ...\n",
       "1366    Cooper's book is yet another warm and fuzzy ma...\n",
       "385     I have many robot books and this is the best a...\n",
       "750     As China re-emerges as a dominant power in the...\n",
       "643     I have been a huge fan of Michael Crichton for...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. You will:\n",
    "\n",
    "1. Prepare your data for your model and create features and a label.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_iter value:  100\n"
     ]
    }
   ],
   "source": [
    "#find best max_iter\n",
    "model = LogisticRegression()\n",
    "param_grid_lr = {'max_iter': [100, 150, 200, 250, 300, 400, 500]}\n",
    "grid_search = GridSearchCV(model, param_grid_lr, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "best_max_iter = grid_search.best_params_['max_iter']\n",
    "print(\"Best max_iter value: \", best_max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on the test data: 0.9161\n",
      "The size of the feature space: 19029\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('my', 11353), ('brother', 2455), ('said', 14836), ('when', 18601)]:\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=100)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "probability_predictions = lr_model.predict_proba(X_test_tfidf)[:,1]\n",
    "class_label_predictions = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "auc = roc_auc_score(y_test, probability_predictions)\n",
    "print('AUC on the test data: {:.4f}'.format(auc))\n",
    "\n",
    "len_feature_space = len(tfidf_vectorizer.vocabulary_)\n",
    "print('The size of the feature space: {0}'.format(len_feature_space))\n",
    "\n",
    "first_five = list(tfidf_vectorizer.vocabulary_.items())[1:5]\n",
    "print('Glimpse of first 5 entries of the mapping of a word to its column/feature index \\n{}:'.format(first_five))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review #1:\n",
      "\n",
      "I've been a fan of Carol Dweck's scholarly work for years. Her work on self-esteem, self-concept, and the incremental vs. entity theories of intelligence provides some of the most powerfully useful tools I've encountered for educators and parents in their work with children, as well as in their own self-awareness and lives. I'm delighted to see this information written here in such a user-friendly conversational tone, rich with stories that illustrate the nuances and complexities of Dweck's research and ideas. I'm recommending this book to all of my graduate students (teachers and principals working with gifted learners), as well as to parents of high-ability children.\n",
      "\n",
      "Dona Matthews, Ph.D., Director of the Hunter College Center for Gifted Studies and Education, City University of New York\n",
      "\n",
      "\n",
      "Prediction: Is this a good review? True\n",
      "\n",
      "Actual: Is this a good review? True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test prediction\n",
    "print('Review #1:\\n')\n",
    "print(X_test.to_numpy()[124])\n",
    "\n",
    "print('\\nPrediction: Is this a good review? {}\\n'.format(class_label_predictions[124])) \n",
    "\n",
    "print('Actual: Is this a good review? {}\\n'.format(y_test.to_numpy()[124]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review #1:\n",
      "\n",
      "Book goes over a lot of information in a very short time, but not much of that information is worth anything unless you're building a circle-track or drag car. Took the hit and ordered Stanforth's Competition Car Suspension\n",
      "\n",
      "\n",
      "Prediction: Is this a good review? False\n",
      "\n",
      "Actual: Is this a good review? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test prediction\n",
    "print('Review #1:\\n')\n",
    "print(X_test.to_numpy()[120])\n",
    "\n",
    "print('\\nPrediction: Is this a good review? {}\\n'.format(class_label_predictions[120])) \n",
    "\n",
    "print('Actual: Is this a good review? {}\\n'.format(y_test.to_numpy()[120]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min Document Frequency Value: 1\n",
      "AUC on the test data: 0.9310\n",
      "The size of the feature space: 143560\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('my', 79875), ('brother', 20610), ('said', 105149), ('when', 137651)]:\n",
      "Glimpse of first 5 stop words \n",
      "[]:\n",
      "\n",
      "Min Document Frequency Value: 10\n",
      "AUC on the test data: 0.9254\n",
      "The size of the feature space: 4257\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('my', 2288), ('brother', 588), ('said', 2967), ('when', 4049)]:\n",
      "Glimpse of first 5 stop words \n",
      "['too comfortable', 'fact in', 'by discarding', 'guidance of']:\n",
      "\n",
      "Min Document Frequency Value: 100\n",
      "AUC on the test data: 0.8625\n",
      "The size of the feature space: 279\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('my', 144), ('when', 258), ('through', 233), ('this', 226)]:\n",
      "Glimpse of first 5 stop words \n",
      "['the war', 'too comfortable', 'fact in', 'by discarding']:\n",
      "\n",
      "Min Document Frequency Value: 1000\n",
      "AUC on the test data: 0.6557\n",
      "The size of the feature space: 10\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('book', 1), ('for', 2), ('to', 9), ('and', 0)]:\n",
      "Glimpse of first 5 stop words \n",
      "['the war', 'too comfortable', 'fact in', 'by discarding']:\n"
     ]
    }
   ],
   "source": [
    "for min_df in [1,10,100,1000]:\n",
    "    print('\\nMin Document Frequency Value: {0}'.format(min_df))\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=min_df, ngram_range=(1,2))\n",
    "    tfidf_vectorizer.fit(X_train)\n",
    "    X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    model = LogisticRegression(max_iter=100)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    probability_predictions = model.predict_proba(X_test_tfidf)[:,1]\n",
    "    auc = roc_auc_score(y_test, probability_predictions)\n",
    "    print('AUC on the test data: {:.4f}'.format(auc))\n",
    "    len_feature_space = len(tfidf_vectorizer.vocabulary_)\n",
    "    print('The size of the feature space: {0}'.format(len_feature_space))\n",
    "    first_five = list(tfidf_vectorizer.vocabulary_.items())[1:5]\n",
    "    print('Glimpse of first 5 entries of the mapping of a word to its column/feature index \\n{}:'.format(first_five))\n",
    "    first_five_stop = list(tfidf_vectorizer.stop_words_)[1:5]\n",
    "    print('Glimpse of first 5 stop words \\n{}:'.format(first_five_stop))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Max Document Frequency Value: 1\n",
      "AUC on the test data: 0.7418\n",
      "The size of the feature space: 105091\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('mushy', 58767), ('dumped', 27415), ('venus', 98087), ('brother said', 15070)]:\n",
      "Glimpse of first 5 stop words \n",
      "['or even', 'the war', 'the promises', 'and brief']:\n",
      "\n",
      "Max Document Frequency Value: 10\n",
      "AUC on the test data: 0.8755\n",
      "The size of the feature space: 139729\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('acting', 2318), ('pretend', 93896), ('dumps', 36257), ('mushy', 77677)]:\n",
      "Glimpse of first 5 stop words \n",
      "['the war', 'of money', 'national', 'aren']:\n",
      "\n",
      "Max Document Frequency Value: 100\n",
      "AUC on the test data: 0.9235\n",
      "The size of the feature space: 143285\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('said', 104967), ('flipping', 45748), ('girls', 50151), ('start', 112862)]:\n",
      "Glimpse of first 5 stop words \n",
      "['might', 'did', 'for', 'the only']:\n",
      "\n",
      "Max Document Frequency Value: 1000\n",
      "AUC on the test data: 0.9326\n",
      "The size of the feature space: 143550\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('my', 79869), ('brother', 20608), ('said', 105142), ('when', 137641)]:\n",
      "Glimpse of first 5 stop words \n",
      "['for', 'book', 'to', 'it']:\n"
     ]
    }
   ],
   "source": [
    "for max_df in [1,10,100,1000]:\n",
    "    print('\\nMax Document Frequency Value: {0}'.format(max_df))\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=max_df, ngram_range=(1,2))\n",
    "    tfidf_vectorizer.fit(X_train)\n",
    "    X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    model = LogisticRegression(max_iter=100)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    probability_predictions = model.predict_proba(X_test_tfidf)[:,1]\n",
    "    auc = roc_auc_score(y_test, probability_predictions)\n",
    "    print('AUC on the test data: {:.4f}'.format(auc))\n",
    "    len_feature_space = len(tfidf_vectorizer.vocabulary_)\n",
    "    print('The size of the feature space: {0}'.format(len_feature_space))\n",
    "    first_five = list(tfidf_vectorizer.vocabulary_.items())[1:5]\n",
    "    print('Glimpse of first 5 entries of the mapping of a word to its column/feature index \\n{}:'.format(first_five))\n",
    "    first_five_stop = list(tfidf_vectorizer.stop_words_)[1:5]\n",
    "    print('Glimpse of first 5 stop words \\n{}:'.format(first_five_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on the test data: 0.9326\n",
      "The size of the feature space: 143550\n",
      "Glimpse of first 5 entries of the mapping of a word to its column/feature index \n",
      "[('my', 79869), ('brother', 20608), ('said', 105142), ('when', 137641)]:\n"
     ]
    }
   ],
   "source": [
    "best_vectorizer = TfidfVectorizer(min_df=1, max_df=1000, ngram_range=(1,2))\n",
    "best_vectorizer.fit(X_train)\n",
    "X_train_best = best_vectorizer.transform(X_train)\n",
    "X_test_best = best_vectorizer.transform(X_test)\n",
    "best_model = LogisticRegression(max_iter=100)\n",
    "best_model.fit(X_train_best, y_train)\n",
    "probability_predictions = best_model.predict_proba(X_test_best)[:,1]\n",
    "class_label_predictions = best_model.predict(X_test_best)\n",
    "\n",
    "auc = roc_auc_score(y_test, probability_predictions)\n",
    "print('AUC on the test data: {:.4f}'.format(auc))\n",
    "\n",
    "len_feature_space = len(tfidf_vectorizer.vocabulary_)\n",
    "print('The size of the feature space: {0}'.format(len_feature_space))\n",
    "\n",
    "first_five = list(tfidf_vectorizer.vocabulary_.items())[1:5]\n",
    "print('Glimpse of first 5 entries of the mapping of a word to its column/feature index \\n{}:'.format(first_five))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review #1:\n",
      "\n",
      "I've been a fan of Carol Dweck's scholarly work for years. Her work on self-esteem, self-concept, and the incremental vs. entity theories of intelligence provides some of the most powerfully useful tools I've encountered for educators and parents in their work with children, as well as in their own self-awareness and lives. I'm delighted to see this information written here in such a user-friendly conversational tone, rich with stories that illustrate the nuances and complexities of Dweck's research and ideas. I'm recommending this book to all of my graduate students (teachers and principals working with gifted learners), as well as to parents of high-ability children.\n",
      "\n",
      "Dona Matthews, Ph.D., Director of the Hunter College Center for Gifted Studies and Education, City University of New York\n",
      "\n",
      "\n",
      "Prediction: Is this a good review? True\n",
      "\n",
      "Actual: Is this a good review? True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test prediction\n",
    "print('Review #1:\\n')\n",
    "print(X_test.to_numpy()[124])\n",
    "\n",
    "print('\\nPrediction: Is this a good review? {}\\n'.format(class_label_predictions[124])) \n",
    "\n",
    "print('Actual: Is this a good review? {}\\n'.format(y_test.to_numpy()[124]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review #1:\n",
      "\n",
      "Book goes over a lot of information in a very short time, but not much of that information is worth anything unless you're building a circle-track or drag car. Took the hit and ordered Stanforth's Competition Car Suspension\n",
      "\n",
      "\n",
      "Prediction: Is this a good review? False\n",
      "\n",
      "Actual: Is this a good review? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test prediction\n",
    "print('Review #1:\\n')\n",
    "print(X_test.to_numpy()[120])\n",
    "\n",
    "print('\\nPrediction: Is this a good review? {}\\n'.format(class_label_predictions[120])) \n",
    "\n",
    "print('Actual: Is this a good review? {}\\n'.format(y_test.to_numpy()[120]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_model_filename = \"Pickle_BookReview_Regression_Model.pkl\"\n",
    "pickle.dump(best_model, open(pkl_model_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persistent_model = pickle.load(open(pkl_model_filename, 'rb'))\n",
    "persistent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True  True False False False  True  True  True False\n",
      "  True  True False  True False False False False False  True False  True\n",
      " False False  True  True False False False False False  True  True False\n",
      "  True False  True  True  True  True False  True False False False  True\n",
      "  True  True False False False False False False  True  True False False\n",
      "  True  True False  True False  True  True False False  True False False\n",
      " False  True  True False False  True False False  True  True False  True\n",
      " False  True False False  True False False False False False False False\n",
      " False  True  True False  True  True  True False  True  True  True  True\n",
      " False False  True False  True  True False False  True  True False  True\n",
      " False  True False False  True False  True  True  True  True  True False\n",
      " False  True False  True  True  True  True False False  True  True  True\n",
      "  True  True False  True False False  True False  True  True  True  True\n",
      " False  True  True False  True  True False  True False  True  True False\n",
      " False  True  True False False False False False  True False False  True\n",
      " False False False False  True False False False  True  True False  True\n",
      "  True False  True  True  True False False False False False  True  True\n",
      " False False  True  True  True  True False  True  True False False  True\n",
      "  True  True  True  True False  True  True  True  True False False  True\n",
      "  True  True  True False  True False  True False False  True False  True\n",
      " False  True  True False  True  True False False False False  True  True\n",
      " False False  True False False  True  True False False  True False False\n",
      " False  True  True  True False False False  True  True False False  True\n",
      "  True  True False  True False False  True  True False False False False\n",
      "  True False False  True  True False  True  True False  True  True  True\n",
      "  True False  True  True False  True False False  True False False False\n",
      " False  True False  True False False  True  True False False  True False\n",
      "  True False  True False False False False  True  True  True False  True\n",
      "  True  True  True  True  True False  True False  True  True  True False\n",
      "  True  True False  True False False  True  True  True False False  True\n",
      " False  True False False False  True  True False False False  True False\n",
      " False False  True False False False False  True  True False False False\n",
      "  True False  True False False False  True  True False  True  True]\n"
     ]
    }
   ],
   "source": [
    "prediction = persistent_model.predict(X_test_best) \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
